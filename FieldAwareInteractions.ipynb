{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d3yo3jpm8FNU"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "import os.path\n",
        "from os import path\n",
        "import collections\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "gdrive_path = '/content/gdrive/My Drive/recommender_dataset'\n",
        "\n",
        "if not path.exists(gdrive_path):\n",
        "  os.mkdir(gdrive_path)\n",
        "\n",
        "os.chdir(gdrive_path)\n",
        "%cd '/content/gdrive/MyDrive/recommender_dataset/'\n",
        "\n",
        "# Set the destination path\n",
        "destination_path='/content/gdrive/MyDrive/recommender_dataset/'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "!mkdir -p \"$destination_path\"\n",
        "\n",
        "# Download the tar.gz file\n",
        "!wget -O \"$destination_path/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\" \"https://go.criteo.net/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\"\n",
        "\n",
        "# Extract the tar.gz file\n",
        "!tar -xzvf \"$destination_path/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\" -C \"$destination_path\"\n",
        "\n",
        "# Remove the downloaded tar.gz file if desired\n",
        "!rm \"$destination_path/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\"\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "destination_path='/content/gdrive/MyDrive/recommender_dataset/'\n",
        "file = destination_path + 'train.txt'\n",
        "print(file)\n",
        "columns = ['label', *(f'I{i}' for i in range(1, 14)), *(f'C{i}' for i in range(1, 27))]\n",
        "df = pd.read_csv(file, nrows=1000000, sep='\\t', names=columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZMaPHoh8YBa",
        "outputId": "91e38416-09da-4d0c-efa5-0ba4373bf9fc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/recommender_dataset/train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "aRfW81Nc8kMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_columns = [f'C{i}' for i in range(1, 27)]\n",
        "int_columns = [f'I{i}' for i in range(1, 14)]"
      ],
      "metadata": {
        "id": "Po9qcSuDAsDX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "X = df.fillna(0)\n",
        "labels = X['label']\n",
        "integer_features = X.iloc[:, 1:14]  # I1-I13\n",
        "categorical_features = X.iloc[:, 14:]  # C1-C26\n",
        "\n",
        "# Convert categorical features to numerical representations (hashing)\n",
        "label_encoders = {}\n",
        "for col in cat_columns:\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    categorical_features[col] = le.fit_transform(categorical_features[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "features = pd.concat([integer_features, categorical_features], axis=1)\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare target and features\n",
        "train_numerical_features = train_data[['I' + str(i) for i in range(1, 14)]]\n",
        "train_categorical_features = train_data[cat_columns]\n",
        "\n",
        "test_numerical_features = test_data[['I' + str(i) for i in range(1, 14)]]\n",
        "test_categorical_features = test_data[cat_columns]"
      ],
      "metadata": {
        "id": "c5YolEBN8na9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_mlp(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(128, activation='relu', input_dim=input_dim),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "54jaEqgABldJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 8\n",
        "num_cat_cols = len(cat_columns)\n",
        "num_int_cols = len(int_columns)\n",
        "\n",
        "input_dim = num_cat_cols + num_int_cols\n",
        "\n",
        "mlp_model = build_mlp(input_dim)\n",
        "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
        "\n",
        "mlp_model.fit(\n",
        "    x=tf.concat([train_categorical_features, train_numerical_features], axis=1),\n",
        "    y=train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1\n",
        ")\n",
        "mlp_model.save('/content/gdrive/MyDrive/recommender_res/q1/mlp_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmx9lVz5CO2r",
        "outputId": "63fc23ee-cc01-478b-b4c1-3e825f8a11e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5625/5625 [==============================] - 54s 9ms/step - loss: 157.6760 - auc: 0.5244 - val_loss: 108.4418 - val_auc: 0.5023\n",
            "Epoch 2/10\n",
            "5625/5625 [==============================] - 56s 10ms/step - loss: 52.4718 - auc: 0.5280 - val_loss: 91.5621 - val_auc: 0.5064\n",
            "Epoch 3/10\n",
            "5625/5625 [==============================] - 31s 6ms/step - loss: 18.0238 - auc: 0.5324 - val_loss: 7.0044 - val_auc: 0.5350\n",
            "Epoch 4/10\n",
            "5625/5625 [==============================] - 19s 3ms/step - loss: 5.7036 - auc: 0.5315 - val_loss: 1.2329 - val_auc: 0.5270\n",
            "Epoch 5/10\n",
            "5625/5625 [==============================] - 20s 4ms/step - loss: 0.8384 - auc: 0.5319 - val_loss: 0.5702 - val_auc: 0.5839\n",
            "Epoch 6/10\n",
            "5625/5625 [==============================] - 19s 3ms/step - loss: 0.5684 - auc: 0.5148 - val_loss: 0.5686 - val_auc: 0.5002\n",
            "Epoch 7/10\n",
            "5625/5625 [==============================] - 19s 3ms/step - loss: 0.5708 - auc: 0.4979 - val_loss: 0.5686 - val_auc: 0.5000\n",
            "Epoch 8/10\n",
            "5625/5625 [==============================] - 21s 4ms/step - loss: 0.5683 - auc: 0.4999 - val_loss: 0.6239 - val_auc: 0.5000\n",
            "Epoch 9/10\n",
            "5625/5625 [==============================] - 23s 4ms/step - loss: 0.5696 - auc: 0.5006 - val_loss: 0.5686 - val_auc: 0.5000\n",
            "Epoch 10/10\n",
            "5625/5625 [==============================] - 52s 9ms/step - loss: 0.5681 - auc: 0.5009 - val_loss: 0.5687 - val_auc: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the dataframe\n",
        "eval_data_mlp = test_data.copy()\n",
        "\n",
        "# Drop the column \"col2\" from the copied dataframe\n",
        "mlp_auc, mlp_loss = mlp_model.evaluate(eval_data_mlp, test_labels)\n",
        "print(\"MLP AUC:\", mlp_auc, \"Loss:\", mlp_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzbjnBezFkI4",
        "outputId": "70e46424-7d12-4e11-a82d-b5a3ee0d75f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6250/6250 [==============================] - 36s 6ms/step - loss: 803.6530 - auc: 0.4881\n",
            "MLP AUC: 803.6530151367188 Loss: 0.4881417751312256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class FactorizationMachine(Layer):\n",
        "    def __init__(self, input_dim, num_factors, **kwargs):\n",
        "        super(FactorizationMachine, self).__init__(**kwargs)\n",
        "        self.input_dim = input_dim\n",
        "        self.num_factors = num_factors\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.V = self.add_weight(name='V',\n",
        "                                 shape=(self.input_dim, self.num_factors),\n",
        "                                 initializer='uniform',\n",
        "                                 trainable=True)\n",
        "        super(FactorizationMachine, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        linear_terms = tf.reduce_sum(inputs, axis=1, keepdims=True)\n",
        "        interactions = 0.5 * tf.reduce_sum(\n",
        "            tf.square(tf.matmul(inputs, self.V) -\n",
        "                      tf.matmul(tf.square(inputs), tf.square(self.V))),\n",
        "            axis=1, keepdims=True)\n",
        "        output = linear_terms + interactions\n",
        "        return output\n",
        "\n",
        "def build_mlp_fm(input_dim, fm_num_factors):\n",
        "    input_layer = keras.layers.Input(shape=(input_dim,))\n",
        "\n",
        "    # MLP layers\n",
        "    mlp = keras.Sequential([\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(64, activation='relu')\n",
        "    ])\n",
        "    mlp_output = mlp(input_layer)\n",
        "\n",
        "    # FM layer\n",
        "    fm_output = FactorizationMachine(input_dim=input_dim, num_factors=fm_num_factors)(input_layer)\n",
        "\n",
        "    # Concatenate MLP and FM outputs\n",
        "    concatenated = keras.layers.Concatenate()([mlp_output, fm_output])\n",
        "\n",
        "    # Final MLP layer\n",
        "    final_output = keras.layers.Dense(1, activation='sigmoid')(concatenated)\n",
        "\n",
        "    model = keras.Model(inputs=input_layer, outputs=final_output)\n",
        "    return model\n",
        "\n",
        "fm_num_factors = 10  # Number of factors for FM\n",
        "\n",
        "mlp_fm_model = build_mlp_fm(input_dim, fm_num_factors)\n",
        "mlp_fm_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OkFsQ7DIz6l",
        "outputId": "8acbab74-5afa-4b4e-ae92-56ed98bb720d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 39)]         0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 64)           13376       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " factorization_machine (Factori  (None, 1)           390         ['input_1[0][0]']                \n",
            " zationMachine)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 65)           0           ['sequential[0][0]',             \n",
            "                                                                  'factorization_machine[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            66          ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,832\n",
            "Trainable params: 13,832\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_fm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
        "\n",
        "mlp_fm_model.fit(\n",
        "    x=tf.concat([train_categorical_features, train_numerical_features], axis=1),\n",
        "    y=train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1\n",
        ")\n",
        "mlp_fm_model.save('/content/gdrive/MyDrive/recommender_res/q2/mlp_fm_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQZkXxPOKl1V",
        "outputId": "bc0ce281-8481-4117-ac37-f55e5d744d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5625/5625 [==============================] - 24s 4ms/step - loss: 18935346888704.0000 - auc: 0.5045 - val_loss: 361718752.0000 - val_auc: 0.5135\n",
            "Epoch 2/10\n",
            "5625/5625 [==============================] - 39s 7ms/step - loss: 70213312.0000 - auc: 0.5208 - val_loss: 987622.6875 - val_auc: 0.5294\n",
            "Epoch 3/10\n",
            "5625/5625 [==============================] - 24s 4ms/step - loss: 216034.5469 - auc: 0.5230 - val_loss: 499648.6250 - val_auc: 0.5047\n",
            "Epoch 4/10\n",
            "5625/5625 [==============================] - 22s 4ms/step - loss: 765967616.0000 - auc: 0.5241 - val_loss: 69775504.0000 - val_auc: 0.5160\n",
            "Epoch 5/10\n",
            "5625/5625 [==============================] - 37s 7ms/step - loss: 10482634.0000 - auc: 0.5288 - val_loss: 12025151.0000 - val_auc: 0.5849\n",
            "Epoch 6/10\n",
            "5625/5625 [==============================] - 51s 9ms/step - loss: 1038822592.0000 - auc: 0.5273 - val_loss: 2375834.5000 - val_auc: 0.5566\n",
            "Epoch 7/10\n",
            "5625/5625 [==============================] - 49s 9ms/step - loss: 2008970624.0000 - auc: 0.5165 - val_loss: 53692.2617 - val_auc: 0.5232\n",
            "Epoch 8/10\n",
            "5625/5625 [==============================] - 35s 6ms/step - loss: 17861296128.0000 - auc: 0.5114 - val_loss: 68125440.0000 - val_auc: 0.5305\n",
            "Epoch 9/10\n",
            "5625/5625 [==============================] - 23s 4ms/step - loss: 131612248.0000 - auc: 0.5023 - val_loss: 69010.1562 - val_auc: 0.5634\n",
            "Epoch 10/10\n",
            "5625/5625 [==============================] - 22s 4ms/step - loss: 398957.5312 - auc: 0.5136 - val_loss: 17583.3320 - val_auc: 0.5031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the dataframe\n",
        "eval_data_mlp_fm = test_data.copy()\n",
        "\n",
        "# Drop the column \"col2\" from the copied dataframe\n",
        "mlp_fm_auc, mlp_fm_loss = mlp_fm_model.evaluate(eval_data_mlp_fm, test_labels)\n",
        "print(\"MLP+FM AUC:\", mlp_fm_auc, \"MLP+FM Loss:\", mlp_fm_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9h-YvCEKwou",
        "outputId": "1ec36b0c-2557-4067-faa7-66370fc41c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6250/6250 [==============================] - 40s 6ms/step - loss: 31842531328.0000 - auc: 0.5000\n",
            "MLP+FM AUC: 31842531328.0 MLP+FM Loss: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Flatten, Concatenate, Reshape\n",
        "\n",
        "def build_fint_model(num_fields, num_categories_per_field, embedding_dim, hidden_units):\n",
        "    inputs = []\n",
        "    embedding_layers = []\n",
        "\n",
        "    for i in range(num_fields):\n",
        "        input_layer = Input(shape=(1,), name=f'field_{i}')\n",
        "        embedding_layer = Embedding(input_dim=num_categories_per_field[i], output_dim=embedding_dim)(input_layer)\n",
        "        inputs.append(input_layer)\n",
        "        embedding_layers.append(embedding_layer)\n",
        "\n",
        "    # Interaction layers for categorical fields\n",
        "    interactions = []\n",
        "    for i in range(num_fields):\n",
        "        for j in range(i + 1, num_fields):\n",
        "            interactions.append(embedding_layers[i] * embedding_layers[j])\n",
        "\n",
        "\n",
        "    field_interactions = Concatenate()(interactions)\n",
        "    field_interactions = Flatten()(field_interactions)\n",
        "\n",
        "    # Concatenate embedding outputs with numeric inputs\n",
        "    combined = Concatenate()([Flatten()(embedding_layer) for embedding_layer in embedding_layers] + [field_interactions])\n",
        "\n",
        "\n",
        "    for units in hidden_units:\n",
        "        combined = Dense(units, activation='relu')(combined)\n",
        "\n",
        "    output_layer = Dense(1, activation='sigmoid')(combined)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "\n",
        "embedding_dim = 8\n",
        "hidden_units = [64, 32]\n",
        "num_cat_per_col = [len(train_data[feature].unique()) for feature in cat_columns]\n",
        "fint_model = build_fint_model(len(num_cat_per_col), num_cat_per_col, embedding_dim, hidden_units)\n",
        "fint_model.summary()\n"
      ],
      "metadata": {
        "id": "WXGPSD0JNCGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Flatten, Concatenate, Reshape\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "# Model Architecture\n",
        "def build_finn_model(num_numeric_features, num_categorical_features, num_categories_per_field, embedding_dim, hidden_units):\n",
        "    # Numeric input\n",
        "    numeric_input = Input(shape=(num_numeric_features,), name='numeric_input')\n",
        "\n",
        "    # Categorical inputs\n",
        "    categorical_inputs = []\n",
        "    embedding_layers = []\n",
        "\n",
        "    for i in range(num_categorical_features):\n",
        "        input_layer = Input(shape=(1,), name=f'categorical_input_{i}')\n",
        "        embedding_layer = Embedding(input_dim=num_categories_per_field[i], output_dim=embedding_dim)(input_layer)\n",
        "        categorical_inputs.append(input_layer)\n",
        "        embedding_layers.append(embedding_layer)\n",
        "\n",
        "    # Field-aware interactions\n",
        "    interactions = []\n",
        "    for i in range(num_categorical_features):\n",
        "        for j in range(i + 1, num_categorical_features):\n",
        "            interactions.append(Flatten()(embedding_layers[i]) * Flatten()(embedding_layers[j]))\n",
        "\n",
        "    field_interactions = Concatenate()(interactions)\n",
        "    field_interactions = Flatten()(field_interactions)\n",
        "\n",
        "\n",
        "    # Combine inputs\n",
        "    combined = Concatenate()([numeric_input, Flatten()(field_interactions)])\n",
        "\n",
        "    # Fully connected layers\n",
        "    for units in hidden_units:\n",
        "        combined = Dense(units, activation='relu')(combined)\n",
        "\n",
        "    # Output layer\n",
        "    output_layer = Dense(1, activation='sigmoid')(combined)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[numeric_input] + categorical_inputs, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Hyperparameters\n",
        "num_numeric_features = 13\n",
        "num_categorical_features = 26\n",
        "num_cat_per_col = [len(train_data[feature].unique()) for feature in cat_columns]\n",
        "embedding_dim = 8\n",
        "hidden_units = [64, 32]\n",
        "\n",
        "# Build the model\n",
        "finn_model = build_finn_model(num_numeric_features, num_categorical_features, num_cat_per_col, embedding_dim, hidden_units)\n",
        "\n",
        "# Compile the model\n",
        "finn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n"
      ],
      "metadata": {
        "id": "wu0raDSAXzKs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finn_model.summary()"
      ],
      "metadata": {
        "id": "XDqUEuM_q10K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "finn_model.fit(\n",
        "    x=[train_numerical_features] + [train_data[col].values for col in cat_columns],\n",
        "    y=train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1\n",
        ")\n",
        "finn_model.save('/content/gdrive/MyDrive/recommender_res/q3/finn_model.h5')"
      ],
      "metadata": {
        "id": "ClNwmW_FOYPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2a68c1-f3b5-4534-8eb1-224a15450453"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5625/5625 [==============================] - 397s 64ms/step - loss: 1.7615 - auc: 0.6913 - val_loss: 0.8776 - val_auc: 0.7309\n",
            "Epoch 2/10\n",
            "5625/5625 [==============================] - 192s 34ms/step - loss: 0.4873 - auc: 0.7998 - val_loss: 0.5105 - val_auc: 0.7241\n",
            "Epoch 3/10\n",
            "5625/5625 [==============================] - 190s 34ms/step - loss: 0.3861 - auc: 0.8607 - val_loss: 0.5141 - val_auc: 0.7349\n",
            "Epoch 4/10\n",
            "5625/5625 [==============================] - 180s 32ms/step - loss: 0.3548 - auc: 0.8839 - val_loss: 0.5147 - val_auc: 0.7487\n",
            "Epoch 5/10\n",
            "5625/5625 [==============================] - 211s 37ms/step - loss: 0.3298 - auc: 0.8986 - val_loss: 0.5363 - val_auc: 0.7491\n",
            "Epoch 6/10\n",
            "5625/5625 [==============================] - 202s 36ms/step - loss: 0.3140 - auc: 0.9085 - val_loss: 0.5454 - val_auc: 0.7366\n",
            "Epoch 7/10\n",
            "5625/5625 [==============================] - 180s 32ms/step - loss: 0.3014 - auc: 0.9157 - val_loss: 0.5440 - val_auc: 0.7418\n",
            "Epoch 8/10\n",
            "5625/5625 [==============================] - 206s 37ms/step - loss: 0.2897 - auc: 0.9217 - val_loss: 0.5706 - val_auc: 0.7322\n",
            "Epoch 9/10\n",
            "5625/5625 [==============================] - 176s 31ms/step - loss: 0.2806 - auc: 0.9268 - val_loss: 0.6195 - val_auc: 0.7286\n",
            "Epoch 10/10\n",
            "5625/5625 [==============================] - 209s 37ms/step - loss: 0.2711 - auc: 0.9317 - val_loss: 0.6189 - val_auc: 0.7325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the dataframe\n",
        "eval_data_mlp_fm = test_data.copy()\n",
        "\n",
        "# Drop the column \"col2\" from the copied dataframe\n",
        "fint_auc, fint_loss = finn_model.evaluate([test_numerical_features] + [eval_data_mlp_fm[col].values for col in cat_columns], test_labels)\n",
        "print(\"FINT AUC:\", fint_auc, \"FINT Loss:\", fint_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfFlqSkbzpko",
        "outputId": "7cc4c0e5-f1cb-45bd-999e-ec3ef108ac96"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6250/6250 [==============================] - 77s 12ms/step - loss: 0.6206 - auc: 0.7294\n",
            "FINT AUC: 0.6205617189407349 FINT Loss: 0.7293546199798584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Models** | MLP | MLP+FM | FINT\n",
        "---    | --- |   ---    | ---\n",
        "**AUC**    | `0.48`|`0.5` |`0.72`\n"
      ],
      "metadata": {
        "id": "sJqIEHY59BdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_top_items(model, user_features, N):\n",
        "    predicted_scores = model.predict(user_features)\n",
        "    top_indices = predicted_scores.argsort()[::-1][:N]\n",
        "    return top_indices\n"
      ],
      "metadata": {
        "id": "AcypFaorATsS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3.2. Recommend any given user to the 5 most relevant items for all implemented\n",
        "models."
      ],
      "metadata": {
        "id": "YU2zUn3gDKZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Define a function to recommend top N items for a given user\n",
        "def recommend_top_items(model, user_features, N):\n",
        "    predicted_scores = model.predict(user_features)\n",
        "    top_indices = predicted_scores.argsort()[::-1][:N]\n",
        "    return top_indices\n",
        "\n",
        "top_N_recommendations = 5\n",
        "\n",
        "mlp_model = keras.models.load_model('/content/gdrive/MyDrive/recommender_res/q1/mlp_model.h5')\n",
        "mlp_recommendations = recommend_top_items(mlp_model, test_data, top_N_recommendations)\n",
        "\n",
        "mlp_fm_model = keras.models.load_model('/content/gdrive/MyDrive/recommender_res/q2/mlp_fm_model.h5', custom_objects={\"FactorizationMachine\": FactorizationMachine})\n",
        "mlp_fm_recommendations = recommend_top_items(mlp_fm_model, test_data, top_N_recommendations)\n",
        "\n",
        "fint_model = keras.models.load_model('/content/gdrive/MyDrive/recommender_res/q3/finn_model.h5')\n",
        "fint_recommendations = recommend_top_items(fint_model, [test_numerical_features] + [test_data[col].values for col in cat_columns], top_N_recommendations)\n",
        "\n",
        "print(\"MLP Recommendations:\", mlp_recommendations)\n",
        "print(\"MLP+FM Recommendations:\", mlp_fm_recommendations)\n",
        "print(\"FINT Recommendations:\", fint_recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjVugDF__jAm",
        "outputId": "b3decc7e-f216-40e4-e519-e8b19ceffb66"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6250/6250 [==============================] - 14s 2ms/step\n",
            "6250/6250 [==============================] - 14s 2ms/step\n",
            "6250/6250 [==============================] - 62s 10ms/step\n",
            "MLP Recommendations: [[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "MLP+FM Recommendations: [[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "FINT Recommendations: [[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Models** | MLP | MLP+FM | FINT\n",
        "---    | --- |   ---    | ---\n",
        "**AUC**    | `0.48`|`0.5` |`0.72`\n"
      ],
      "metadata": {
        "id": "0fSfrkJSD2Ra"
      }
    }
  ]
}