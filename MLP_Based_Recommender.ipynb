{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d3yo3jpm8FNU"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "import os.path\n",
        "from os import path\n",
        "import collections\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "gdrive_path = '/content/gdrive/My Drive/recommender_dataset'\n",
        "\n",
        "if not path.exists(gdrive_path):\n",
        "  os.mkdir(gdrive_path)\n",
        "\n",
        "os.chdir(gdrive_path)\n",
        "%cd '/content/gdrive/MyDrive/recommender_dataset/'\n",
        "\n",
        "# Set the destination path\n",
        "destination_path='/content/gdrive/MyDrive/recommender_dataset/'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "!mkdir -p \"$destination_path\"\n",
        "\n",
        "# Download the tar.gz file\n",
        "!wget -O \"$destination_path/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\" \"https://go.criteo.net/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\"\n",
        "\n",
        "# Extract the tar.gz file\n",
        "!tar -xzvf \"$destination_path/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\" -C \"$destination_path\"\n",
        "\n",
        "# Remove the downloaded tar.gz file if desired\n",
        "!rm \"$destination_path/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\"\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "destination_path='/content/gdrive/MyDrive/recommender_dataset/'\n",
        "file = destination_path + 'train.txt'\n",
        "print(file)\n",
        "columns = ['label', *(f'I{i}' for i in range(1, 14)), *(f'C{i}' for i in range(1, 27))]\n",
        "df = pd.read_csv(file, nrows=1000000, sep='\\t', names=columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZMaPHoh8YBa",
        "outputId": "3657a211-cded-4b9e-c0c8-16672b2977e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/recommender_dataset/train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "aRfW81Nc8kMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_columns = [f'C{i}' for i in range(1, 27)]\n",
        "int_columns = [f'I{i}' for i in range(1, 14)]"
      ],
      "metadata": {
        "id": "Po9qcSuDAsDX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "X = df.fillna(0)\n",
        "labels = X['label']\n",
        "integer_features = X.iloc[:, 1:14]  # I1-I13\n",
        "categorical_features = X.iloc[:, 14:]  # C1-C26\n",
        "\n",
        "# Convert categorical features to numerical representations (hashing)\n",
        "label_encoders = {}\n",
        "for col in cat_columns:\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    categorical_features[col] = le.fit_transform(categorical_features[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "features = pd.concat([integer_features, categorical_features], axis=1)\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare target and features\n",
        "train_numerical_features = train_data[['I' + str(i) for i in range(1, 14)]]\n",
        "train_categorical_features = train_data[cat_columns]\n",
        "\n",
        "test_numerical_features = test_data[['I' + str(i) for i in range(1, 14)]]\n",
        "test_categorical_features = test_data[cat_columns]"
      ],
      "metadata": {
        "id": "c5YolEBN8na9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_mlp(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(128, activation='relu', input_dim=input_dim),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "54jaEqgABldJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 8\n",
        "num_cat_cols = len(cat_columns)\n",
        "num_int_cols = len(int_columns)\n",
        "\n",
        "input_dim = num_cat_cols + num_int_cols\n",
        "\n",
        "mlp_model = build_mlp(input_dim)\n",
        "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
        "\n",
        "mlp_model.fit(\n",
        "    x=tf.concat([train_categorical_features, train_numerical_features], axis=1),\n",
        "    y=train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1\n",
        ")\n",
        "mlp_model.save('/content/gdrive/MyDrive/recommender_res/q1/mlp_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmx9lVz5CO2r",
        "outputId": "63fc23ee-cc01-478b-b4c1-3e825f8a11e3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5625/5625 [==============================] - 54s 9ms/step - loss: 157.6760 - auc: 0.5244 - val_loss: 108.4418 - val_auc: 0.5023\n",
            "Epoch 2/10\n",
            "5625/5625 [==============================] - 56s 10ms/step - loss: 52.4718 - auc: 0.5280 - val_loss: 91.5621 - val_auc: 0.5064\n",
            "Epoch 3/10\n",
            "5625/5625 [==============================] - 31s 6ms/step - loss: 18.0238 - auc: 0.5324 - val_loss: 7.0044 - val_auc: 0.5350\n",
            "Epoch 4/10\n",
            "5625/5625 [==============================] - 19s 3ms/step - loss: 5.7036 - auc: 0.5315 - val_loss: 1.2329 - val_auc: 0.5270\n",
            "Epoch 5/10\n",
            "5625/5625 [==============================] - 20s 4ms/step - loss: 0.8384 - auc: 0.5319 - val_loss: 0.5702 - val_auc: 0.5839\n",
            "Epoch 6/10\n",
            "5625/5625 [==============================] - 19s 3ms/step - loss: 0.5684 - auc: 0.5148 - val_loss: 0.5686 - val_auc: 0.5002\n",
            "Epoch 7/10\n",
            "5625/5625 [==============================] - 19s 3ms/step - loss: 0.5708 - auc: 0.4979 - val_loss: 0.5686 - val_auc: 0.5000\n",
            "Epoch 8/10\n",
            "5625/5625 [==============================] - 21s 4ms/step - loss: 0.5683 - auc: 0.4999 - val_loss: 0.6239 - val_auc: 0.5000\n",
            "Epoch 9/10\n",
            "5625/5625 [==============================] - 23s 4ms/step - loss: 0.5696 - auc: 0.5006 - val_loss: 0.5686 - val_auc: 0.5000\n",
            "Epoch 10/10\n",
            "5625/5625 [==============================] - 52s 9ms/step - loss: 0.5681 - auc: 0.5009 - val_loss: 0.5687 - val_auc: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the dataframe\n",
        "eval_data_mlp = test_data.copy()\n",
        "\n",
        "# Drop the column \"col2\" from the copied dataframe\n",
        "mlp_auc, mlp_loss = mlp_model.evaluate(eval_data_mlp, test_labels)\n",
        "print(\"MLP AUC:\", mlp_auc, \"Loss:\", mlp_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzbjnBezFkI4",
        "outputId": "70e46424-7d12-4e11-a82d-b5a3ee0d75f3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6250/6250 [==============================] - 36s 6ms/step - loss: 803.6530 - auc: 0.4881\n",
            "MLP AUC: 803.6530151367188 Loss: 0.4881417751312256\n"
          ]
        }
      ]
    }
  ]
}