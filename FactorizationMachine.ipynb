{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d3yo3jpm8FNU"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "import os.path\n",
        "from os import path\n",
        "import collections\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "gdrive_path = '/content/gdrive/My Drive/recommender_dataset'\n",
        "\n",
        "if not path.exists(gdrive_path):\n",
        "  os.mkdir(gdrive_path)\n",
        "\n",
        "os.chdir(gdrive_path)\n",
        "%cd '/content/gdrive/MyDrive/recommender_dataset/'\n",
        "\n",
        "# Set the destination path\n",
        "destination_path='/content/gdrive/MyDrive/recommender_dataset/'\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "!mkdir -p \"$destination_path\"\n",
        "\n",
        "# Download the tar.gz file\n",
        "!wget -O \"$destination_path/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\" \"https://go.criteo.net/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\"\n",
        "\n",
        "# Extract the tar.gz file\n",
        "!tar -xzvf \"$destination_path/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\" -C \"$destination_path\"\n",
        "\n",
        "# Remove the downloaded tar.gz file if desired\n",
        "!rm \"$destination_path/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz\"\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "destination_path='/content/gdrive/MyDrive/recommender_dataset/'\n",
        "file = destination_path + 'train.txt'\n",
        "print(file)\n",
        "columns = ['label', *(f'I{i}' for i in range(1, 14)), *(f'C{i}' for i in range(1, 27))]\n",
        "df = pd.read_csv(file, nrows=1000000, sep='\\t', names=columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZMaPHoh8YBa",
        "outputId": "3657a211-cded-4b9e-c0c8-16672b2977e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/recommender_dataset/train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "aRfW81Nc8kMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_columns = [f'C{i}' for i in range(1, 27)]\n",
        "int_columns = [f'I{i}' for i in range(1, 14)]"
      ],
      "metadata": {
        "id": "Po9qcSuDAsDX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "X = df.fillna(0)\n",
        "labels = X['label']\n",
        "integer_features = X.iloc[:, 1:14]  # I1-I13\n",
        "categorical_features = X.iloc[:, 14:]  # C1-C26\n",
        "\n",
        "# Convert categorical features to numerical representations (hashing)\n",
        "label_encoders = {}\n",
        "for col in cat_columns:\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    categorical_features[col] = le.fit_transform(categorical_features[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "features = pd.concat([integer_features, categorical_features], axis=1)\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare target and features\n",
        "train_numerical_features = train_data[['I' + str(i) for i in range(1, 14)]]\n",
        "train_categorical_features = train_data[cat_columns]\n",
        "\n",
        "test_numerical_features = test_data[['I' + str(i) for i in range(1, 14)]]\n",
        "test_categorical_features = test_data[cat_columns]"
      ],
      "metadata": {
        "id": "c5YolEBN8na9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_mlp(input_dim):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(128, activation='relu', input_dim=input_dim),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "54jaEqgABldJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 8\n",
        "num_cat_cols = len(cat_columns)\n",
        "num_int_cols = len(int_columns)\n",
        "\n",
        "input_dim = num_cat_cols + num_int_cols\n",
        "\n",
        "mlp_model = build_mlp(input_dim)\n",
        "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
        "\n",
        "mlp_model.fit(\n",
        "    x=tf.concat([train_categorical_features, train_numerical_features], axis=1),\n",
        "    y=train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1\n",
        ")\n",
        "mlp_model.save('/content/gdrive/MyDrive/recommender_res/q1/mlp_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmx9lVz5CO2r",
        "outputId": "63fc23ee-cc01-478b-b4c1-3e825f8a11e3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5625/5625 [==============================] - 54s 9ms/step - loss: 157.6760 - auc: 0.5244 - val_loss: 108.4418 - val_auc: 0.5023\n",
            "Epoch 2/10\n",
            "5625/5625 [==============================] - 56s 10ms/step - loss: 52.4718 - auc: 0.5280 - val_loss: 91.5621 - val_auc: 0.5064\n",
            "Epoch 3/10\n",
            "5625/5625 [==============================] - 31s 6ms/step - loss: 18.0238 - auc: 0.5324 - val_loss: 7.0044 - val_auc: 0.5350\n",
            "Epoch 4/10\n",
            "5625/5625 [==============================] - 19s 3ms/step - loss: 5.7036 - auc: 0.5315 - val_loss: 1.2329 - val_auc: 0.5270\n",
            "Epoch 5/10\n",
            "5625/5625 [==============================] - 20s 4ms/step - loss: 0.8384 - auc: 0.5319 - val_loss: 0.5702 - val_auc: 0.5839\n",
            "Epoch 6/10\n",
            "5625/5625 [==============================] - 19s 3ms/step - loss: 0.5684 - auc: 0.5148 - val_loss: 0.5686 - val_auc: 0.5002\n",
            "Epoch 7/10\n",
            "5625/5625 [==============================] - 19s 3ms/step - loss: 0.5708 - auc: 0.4979 - val_loss: 0.5686 - val_auc: 0.5000\n",
            "Epoch 8/10\n",
            "5625/5625 [==============================] - 21s 4ms/step - loss: 0.5683 - auc: 0.4999 - val_loss: 0.6239 - val_auc: 0.5000\n",
            "Epoch 9/10\n",
            "5625/5625 [==============================] - 23s 4ms/step - loss: 0.5696 - auc: 0.5006 - val_loss: 0.5686 - val_auc: 0.5000\n",
            "Epoch 10/10\n",
            "5625/5625 [==============================] - 52s 9ms/step - loss: 0.5681 - auc: 0.5009 - val_loss: 0.5687 - val_auc: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the dataframe\n",
        "eval_data_mlp = test_data.copy()\n",
        "\n",
        "# Drop the column \"col2\" from the copied dataframe\n",
        "mlp_auc, mlp_loss = mlp_model.evaluate(eval_data_mlp, test_labels)\n",
        "print(\"MLP AUC:\", mlp_auc, \"Loss:\", mlp_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzbjnBezFkI4",
        "outputId": "70e46424-7d12-4e11-a82d-b5a3ee0d75f3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6250/6250 [==============================] - 36s 6ms/step - loss: 803.6530 - auc: 0.4881\n",
            "MLP AUC: 803.6530151367188 Loss: 0.4881417751312256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class FactorizationMachine(Layer):\n",
        "    def __init__(self, input_dim, num_factors, **kwargs):\n",
        "        super(FactorizationMachine, self).__init__(**kwargs)\n",
        "        self.input_dim = input_dim\n",
        "        self.num_factors = num_factors\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.V = self.add_weight(name='V',\n",
        "                                 shape=(self.input_dim, self.num_factors),\n",
        "                                 initializer='uniform',\n",
        "                                 trainable=True)\n",
        "        super(FactorizationMachine, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        linear_terms = tf.reduce_sum(inputs, axis=1, keepdims=True)\n",
        "        interactions = 0.5 * tf.reduce_sum(\n",
        "            tf.square(tf.matmul(inputs, self.V) -\n",
        "                      tf.matmul(tf.square(inputs), tf.square(self.V))),\n",
        "            axis=1, keepdims=True)\n",
        "        output = linear_terms + interactions\n",
        "        return output\n",
        "\n",
        "def build_mlp_fm(input_dim, fm_num_factors):\n",
        "    input_layer = keras.layers.Input(shape=(input_dim,))\n",
        "\n",
        "    # MLP layers\n",
        "    mlp = keras.Sequential([\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(64, activation='relu')\n",
        "    ])\n",
        "    mlp_output = mlp(input_layer)\n",
        "\n",
        "    # FM layer\n",
        "    fm_output = FactorizationMachine(input_dim=input_dim, num_factors=fm_num_factors)(input_layer)\n",
        "\n",
        "    # Concatenate MLP and FM outputs\n",
        "    concatenated = keras.layers.Concatenate()([mlp_output, fm_output])\n",
        "\n",
        "    # Final MLP layer\n",
        "    final_output = keras.layers.Dense(1, activation='sigmoid')(concatenated)\n",
        "\n",
        "    model = keras.Model(inputs=input_layer, outputs=final_output)\n",
        "    return model\n",
        "\n",
        "fm_num_factors = 10  # Number of factors for FM\n",
        "\n",
        "mlp_fm_model = build_mlp_fm(input_dim, fm_num_factors)\n",
        "mlp_fm_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OkFsQ7DIz6l",
        "outputId": "4b925949-a2c7-446c-9790-00608146f6d2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 39)]         0           []                               \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 64)           13376       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " factorization_machine (Factori  (None, 1)           390         ['input_1[0][0]']                \n",
            " zationMachine)                                                                                   \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 65)           0           ['sequential_2[0][0]',           \n",
            "                                                                  'factorization_machine[0][0]']  \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 1)            66          ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,832\n",
            "Trainable params: 13,832\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_fm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
        "\n",
        "mlp_fm_model.fit(\n",
        "    x=tf.concat([train_categorical_features, train_numerical_features], axis=1),\n",
        "    y=train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1\n",
        ")\n",
        "mlp_fm_model.save('/content/gdrive/MyDrive/recommender_res/q2/mlp_fm_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQZkXxPOKl1V",
        "outputId": "bc0ce281-8481-4117-ac37-f55e5d744d34"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5625/5625 [==============================] - 24s 4ms/step - loss: 18935346888704.0000 - auc: 0.5045 - val_loss: 361718752.0000 - val_auc: 0.5135\n",
            "Epoch 2/10\n",
            "5625/5625 [==============================] - 39s 7ms/step - loss: 70213312.0000 - auc: 0.5208 - val_loss: 987622.6875 - val_auc: 0.5294\n",
            "Epoch 3/10\n",
            "5625/5625 [==============================] - 24s 4ms/step - loss: 216034.5469 - auc: 0.5230 - val_loss: 499648.6250 - val_auc: 0.5047\n",
            "Epoch 4/10\n",
            "5625/5625 [==============================] - 22s 4ms/step - loss: 765967616.0000 - auc: 0.5241 - val_loss: 69775504.0000 - val_auc: 0.5160\n",
            "Epoch 5/10\n",
            "5625/5625 [==============================] - 37s 7ms/step - loss: 10482634.0000 - auc: 0.5288 - val_loss: 12025151.0000 - val_auc: 0.5849\n",
            "Epoch 6/10\n",
            "5625/5625 [==============================] - 51s 9ms/step - loss: 1038822592.0000 - auc: 0.5273 - val_loss: 2375834.5000 - val_auc: 0.5566\n",
            "Epoch 7/10\n",
            "5625/5625 [==============================] - 49s 9ms/step - loss: 2008970624.0000 - auc: 0.5165 - val_loss: 53692.2617 - val_auc: 0.5232\n",
            "Epoch 8/10\n",
            "5625/5625 [==============================] - 35s 6ms/step - loss: 17861296128.0000 - auc: 0.5114 - val_loss: 68125440.0000 - val_auc: 0.5305\n",
            "Epoch 9/10\n",
            "5625/5625 [==============================] - 23s 4ms/step - loss: 131612248.0000 - auc: 0.5023 - val_loss: 69010.1562 - val_auc: 0.5634\n",
            "Epoch 10/10\n",
            "5625/5625 [==============================] - 22s 4ms/step - loss: 398957.5312 - auc: 0.5136 - val_loss: 17583.3320 - val_auc: 0.5031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the dataframe\n",
        "eval_data_mlp_fm = test_data.copy()\n",
        "\n",
        "# Drop the column \"col2\" from the copied dataframe\n",
        "mlp_fm_auc, mlp_fm_loss = mlp_fm_model.evaluate(eval_data_mlp_fm, test_labels)\n",
        "print(\"MLP+FM AUC:\", mlp_fm_auc, \"MLP+FM Loss:\", mlp_fm_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9h-YvCEKwou",
        "outputId": "1ec36b0c-2557-4067-faa7-66370fc41c42"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6250/6250 [==============================] - 40s 6ms/step - loss: 31842531328.0000 - auc: 0.5000\n",
            "MLP+FM AUC: 31842531328.0 MLP+FM Loss: 0.5\n"
          ]
        }
      ]
    }
  ]
}